{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify datajson\n",
    "import torch\n",
    "import os \n",
    "import json \n",
    "datajson_path_makeup = '/media/pc/hengda1t/hengda/datasets/MT-Dataset/images/mirror_makeup/mirror_makeup_dataset.json'\n",
    "datajson_path_non_makeup = '/media/pc/hengda1t/hengda/datasets/MT-Dataset/images/mirror_non_makeup/mirror_non_makeup_dataset.json'\n",
    "\n",
    "with open(datajson_path_non_makeup,'r') as f:\n",
    "    datajson_non_makeup = json.load(f)\n",
    "with open(datajson_path_makeup,'r') as f:\n",
    "    datajson_makeup = json.load(f)\n",
    "\n",
    "print(len(datajson_non_makeup['labels']))\n",
    "for x in datajson_makeup['labels']:\n",
    "    datajson_non_makeup['labels'].append(x)\n",
    "with open ('/media/pc/hengda1t/hengda/datasets/MT-Dataset/images/mirror_non_makeup/all_mt_dataset.json','w') as f:\n",
    "   json.dump(datajson_non_makeup,f)\n",
    "print(len(datajson_non_makeup['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.]]])\n",
      "tensor(2.5000)\n",
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "loss_l1 = nn.L1Loss()\n",
    "a = torch.tensor([[2,3],[4,5]]).float()\n",
    "b = torch.ones_like(a).float()\n",
    "print(a)\n",
    "c = torch.tensor([[[2,3],[4,5]],[[2,3],[4,5]]]).float()\n",
    "print(c.shape)\n",
    "d = torch.ones_like(c).float()\n",
    "print(d)\n",
    "a_loss = loss_l1(a,b)\n",
    "b_loss = loss_l1(c,d)\n",
    "print(a_loss)\n",
    "print(b_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder result latents  .pt-> .npy\n",
    "import torch \n",
    "import numpy as np \n",
    "path = '/media/pc/hengda1t/hengda/e4e_eg3d/save_encoder/inversions/latents/'\n",
    "dest_path = '/media/pc/hengda1t/hengda/EG3D-projector/eg3d/projector_out/encoder'\n",
    "files = os.listdir(path)\n",
    "for file in files:\n",
    "    files_path = os.path.join(path,file)\n",
    "    tmp = torch.load(files_path)\n",
    "    tmp_npy = tmp.numpy()\n",
    "    np.save(os.path.join(dest_path,file.replace('.pt','.npy')),tmp_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "root = '/media/pc/hengda1t/hengda/datasets/test_cele'\n",
    "dataset_json = os.path.join(root,'dataset.json')\n",
    "root_pngs = os.listdir(root)\n",
    "with open(dataset_json,'r') as f :\n",
    "    dataset = json.load(f)\n",
    "    dataset_labels = dict(dataset['labels'])\n",
    "\n",
    "for file in root_pngs:\n",
    "    if '.png' in file:\n",
    "        camera = dataset_labels[file]      \n",
    "        np.save(os.path.join(root,file.replace('.png','.npy')),np.array(camera,np.float32))\n",
    "\n",
    "\n",
    "    print('is over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latent code by optimization\n",
    "\n",
    "import os\n",
    "path_test_imgs = '/media/pc/hengda1t/hengda/datasets/test_cele/'\n",
    "files = os.listdir(path_test_imgs)\n",
    "print(len(files))\n",
    "for file in files:\n",
    "    if '.png' in file:\n",
    "        path_file = os.path.join(path_test_imgs,file)\n",
    "        cmd = f'CUDA_VISIBLE_DEVICES=0 python ./run_projector.py --image_path {path_file} --datajson /media/pc/hengda1t/hengda/datasets/test_cele/dataset.json --latent_space_type w_plus --outdir=optimizer --network ../pretrained_models/ffhq512-128.pkl'\n",
    "        os.system(cmd)       \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wyq_eg3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd8aa1e353085ab8c9d6acf1eecd95a62bbd8c85e2ba57ed7c25982a5575dde6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
