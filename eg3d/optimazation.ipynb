{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use optimazation to find the best quality\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import dnnlib\n",
    "import legacy\n",
    "import numpy as np \n",
    "import tqdm\n",
    "dataset_json = '/media/pc/hengda1t/hengda/datasets/MT-Dataset/images/mirror_non_makeup/all_mt_dataset.json'\n",
    "# input params\n",
    "target_img_path = ''\n",
    "num_steps = 10000\n",
    "\n",
    "c_basename = os.path.basename(target_img_path)\n",
    "network_pkl = '../pretrained_models/ffhq512-128.pkl'\n",
    "device = torch.device('cuda')\n",
    "# load eg3d decoder\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\n",
    "    G.eval()\n",
    "# Compute w stats.\n",
    "w_avg_samples = 1000\n",
    "z_samples = np.random.RandomState(123).randn(w_avg_samples, G.z_dim)\n",
    "w_samples = G.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)  # [N, 1, C]\n",
    "w_avg = np.mean(w_samples, axis=0, keepdims=True)  # [1, 1, C]\n",
    "w_std = (np.sum((w_samples - w_avg) ** 2) / w_avg_samples) ** 0.5\n",
    "start_w = w_avg\n",
    "\n",
    "\n",
    "#load camera\n",
    "with open(dataset_json, 'r') as f:\n",
    "    camera_dic = dict(json.load(f)['labels'])\n",
    "\n",
    "c = camera_dic[c_basename]\n",
    "\n",
    "# init w_opt\n",
    "w_opt = torch.tensor(start_w, dtype=torch.float32, device=device,\n",
    "                         requires_grad=True)  # pylint: disable=not-callable\n",
    "\n",
    "# init optimizer\n",
    "optimizer = torch.optim.Adam([w_opt] , betas=(0.9, 0.999),\n",
    "                                 lr=5e-3)\n",
    "\n",
    "\n",
    "# give a latent\n",
    "latent = torch.randn(1,14,512).to(device)\n",
    "for step in tqdm(range(num_steps)):\n",
    "    # Learning rate schedule.\n",
    "    t = step / num_steps\n",
    "    w_noise_scale = w_std * initial_noise_factor * max(0.0, 1.0 - t / noise_ramp_length) ** 2\n",
    "    lr_ramp = min(1.0, (1.0 - t) / lr_rampdown_length)\n",
    "    lr_ramp = 0.5 - 0.5 * np.cos(lr_ramp * np.pi)\n",
    "    lr_ramp = lr_ramp * min(1.0, t / lr_rampup_length)\n",
    "    lr = initial_learning_rate * lr_ramp\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "# go a generator\n",
    "\n",
    "    img = G.synthesis(latent, c, noise_mode='const')['image']\n",
    "\n",
    "\n",
    "\n",
    "# design loss\n",
    "\n",
    "\n",
    "#optimaze the code \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('wyq_eg3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd8aa1e353085ab8c9d6acf1eecd95a62bbd8c85e2ba57ed7c25982a5575dde6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
